---
title: "Pretraining Language Models for Diachronic Linguistic Change Discovery"
author: 
- Elisabeth Fittschen
- Sabrina Li
- Tom Lippincott
- Leshem Choshsem
- Craig Messner

pdf_path: "paper_pdfs/2504.05523v1.pdf"
read: False
reasons_to_read:
  - todo
concise_description: >
  todo
questions:
  - todo
topics:
  topic_1: >
    reason, why this fits into topic_1
abstract: >
  "Large language models (LLMs) have shown potential as tools for scientificdiscovery. This has engendered growing interest in their use in humanisticdisciplines, such as historical linguistics and literary studies. These fieldsoften construct arguments on the basis of delineations like genre, or moreinflexibly, time period. Although efforts have been made to restrict inferenceto specific domains via fine-tuning or model editing, we posit that the onlytrue guarantee is domain-restricted pretraining -- typically, a data- andcompute-expensive proposition.  We show that efficient pretraining techniques can produce useful models overcorpora too large for easy manual inspection but too small for "typical" LLMapproaches. We employ a novel date-attribution pipeline in order to obtain atemporally-segmented dataset of five 10-million-word slices. We train twocorresponding five-model batteries over these corpus segments, efficientpretraining and Llama3-8B parameter efficiently finetuned.  We find that the pretrained models are faster to train than the finetunedbaselines and that they better respect the historical divisions of our corpus.Emphasizing speed and precision over a-historical comprehensiveness enables anumber of novel approaches to hypothesis discovery and testing in our targetfields. Taking up diachronic linguistics as a testbed, we show that our methodenables the detection of a diverse set of phenomena, including en masse lexicalchange, non-lexical (grammatical and morphological) change, and word senseintroduction/obsolescence. We provide a ready-to-use pipeline that allowsextension of our approach to other target fields with only minimal adaptation."
---
# Pretraining Language Models for Diachronic Linguistic Change Discovery ([pdf](paper_pdfs/2504.05523v1.pdf))
### Your thoughts below:
---
todo